version: '3.8'

x-clickhouse-defaults:
  &clickhouse-defaults
  restart: on-failure
  image: clickhouse/clickhouse-server:22.8.8-alpine
  tty: true
  depends_on:
    - zookeeper-1
    # - zookeeper-2
    # - zookeeper-3
  logging:
    options:
      max-size: 50m
      max-file: "3"
  healthcheck:
    # "clickhouse", "client", "-u ${CLICKHOUSE_USER}", "--password ${CLICKHOUSE_PASSWORD}", "-q 'SELECT 1'"
    test:
      [
        "CMD",
        "wget",
        "--spider",
        "-q",
        "localhost:8123/ping"
      ]
    interval: 30s
    timeout: 5s
    retries: 3
  ulimits:
    nproc: 65535
    nofile:
      soft: 262144
      hard: 262144

x-clickhouse-depend:
  &clickhouse-depend
  depends_on:
    clickhouse:
      condition: service_healthy
    # clickhouse-2:
    #   condition: service_healthy
    # clickhouse-3:
    #   condition: service_healthy

services:
  apisix:
    image: apache/apisix:${APISIX_IMAGE_TAG:-3.2.0-debian}
    restart: always
    volumes:
      - ./apisix_conf/config.yaml:/usr/local/apisix/conf/config.yaml:ro
      - ./apisix_conf/apisix.yaml:/usr/local/apisix/conf/apisix.yaml:ro
      # - ./otlp.lua://usr/local/apisix/deps/share/lua/5.1/opentelemetry/trace/exporter/otlp.lua
    ports:
      - "9180:9180/tcp"
      - "9080:9080/tcp"
      - "9091:9091/tcp"
      - "9443:9443/tcp"
      - "9092:9092/tcp"

  prometheus:
    image: prom/prometheus:v2.25.0
    restart: always
    volumes:
      - ./prometheus_conf/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  # grafana:
  #   image: grafana/grafana:7.3.7
  #   restart: always
  #   ports:
  #     - "3000:3000"
  #   volumes:
  #     - "./grafana_conf/provisioning:/etc/grafana/provisioning"
  #     - "./grafana_conf/dashboards:/var/lib/grafana/dashboards"
  #     - "./grafana_conf/config/grafana.ini:/etc/grafana/grafana.ini"

  auth-server:
    image: quay.io/keycloak/keycloak:21.0.1
    environment:
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
    command: start-dev --import-realm
    volumes:
      - ./keycloak/import/:/opt/keycloak/data/import
    ports:
      - "8080:8080"

  eventstore:
    image: eventstore/eventstore:21.10.0-buster-slim
    environment:
      - EVENTSTORE_CLUSTER_SIZE=1
      - EVENTSTORE_RUN_PROJECTIONS=All
      - EVENTSTORE_START_STANDARD_PROJECTIONS=true
      - EVENTSTORE_EXT_TCP_PORT=1113
      - EVENTSTORE_HTTP_PORT=2113
      - EVENTSTORE_INSECURE=true
      - EVENTSTORE_ENABLE_EXTERNAL_TCP=true
      - EVENTSTORE_ENABLE_ATOM_PUB_OVER_HTTP=true
    ports:
      - "1113:1113"
      - "2113:2113"
    volumes:
      - type: volume
        source: eventstore-volume-data
        target: /var/lib/eventstore
      - type: volume
        source: eventstore-volume-logs
        target: /var/log/eventstore

  #######################################################
  ##########         SIGNOZ          ####################
  #######################################################
  zookeeper-1:
    image: bitnami/zookeeper:3.7.0
    container_name: zookeeper-1
    hostname: zookeeper-1
    user: root
    ports:
      - "2181:2181"
      - "2888:2888"
      - "3888:3888"
    volumes:
      - ./signoz_conf/data/zookeeper-1:/bitnami/zookeeper
    environment:
      - ZOO_SERVER_ID=1
      # - ZOO_SERVERS=0.0.0.0:2888:3888,zookeeper-2:2888:3888,zookeeper-3:2888:3888
      - ALLOW_ANONYMOUS_LOGIN=yes
      - ZOO_AUTOPURGE_INTERVAL=1
  clickhouse:
    <<: *clickhouse-defaults
    container_name: clickhouse
    hostname: clickhouse
    ports:
      - "9000:9000"
      - "8123:8123"
      - "9181:9181"
    volumes:
      - ./signoz_conf/clickhouse-config.xml:/etc/clickhouse-server/config.xml
      - ./signoz_conf/clickhouse-users.xml:/etc/clickhouse-server/users.xml
      - ./signoz_conf/custom-function.xml:/etc/clickhouse-server/custom-function.xml
      - ./signoz_conf/clickhouse-cluster.xml:/etc/clickhouse-server/config.d/cluster.xml
      # - ./clickhouse-storage.xml:/etc/clickhouse-server/config.d/storage.xml
      - ./signoz_conf/data/clickhouse/:/var/lib/clickhouse/
      - ./signoz_conf/user_scripts:/var/lib/clickhouse/user_scripts/

  alertmanager:
    image: signoz/alertmanager:${ALERTMANAGER_TAG:-0.23.0-0.2}
    volumes:
      - ./signoz_conf/data/alertmanager:/data
    depends_on:
      query-service:
        condition: service_healthy
    restart: on-failure
    command:
      - --queryService.url=http://query-service:8085
      - --storage.path=/data

  query-service:
    image: signoz/query-service:${DOCKER_TAG:-0.18.1}
    container_name: query-service
    command: [ "-config=/root/config/prometheus.yml" ]
    # ports:
    #   - "6060:6060"     # pprof port
    #   - "8080:8080"     # query-service port
    volumes:
      - ./signoz_conf/prometheus.yml:/root/config/prometheus.yml
      - ./signoz_conf/dashboards:/root/config/dashboards
      - ./signoz_conf/data/signoz/:/var/lib/signoz/
    environment:
      - ClickHouseUrl=tcp://clickhouse:9000/?database=signoz_traces
      - ALERTMANAGER_API_PREFIX=http://alertmanager:9093/api/
      - SIGNOZ_LOCAL_DB_PATH=/var/lib/signoz/signoz.db
      - DASHBOARDS_PATH=/root/config/dashboards
      - STORAGE=clickhouse
      - GODEBUG=netdns=go
      - TELEMETRY_ENABLED=true
      - DEPLOYMENT_TYPE=docker-standalone-amd
    restart: on-failure
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--spider",
          "-q",
          "localhost:8080/api/v1/health"
        ]
      interval: 30s
      timeout: 5s
      retries: 3
    <<: *clickhouse-depend

  signoz-frontend:
    image: signoz/frontend:${DOCKER_TAG:-0.18.1}
    container_name: frontend
    restart: on-failure
    depends_on:
      - alertmanager
      - query-service
    ports:
      - "3301:3301"
    volumes:
      - ./signoz_conf/nginx-config.conf:/etc/nginx/conf.d/default.conf

  otel-collector:
    image: signoz/signoz-otel-collector:${OTELCOL_TAG:-0.66.7}
    command: [ "--config=/etc/otel-collector-config.yaml" ]
    user: root # required for reading docker container logs
    volumes:
      - ./signoz_conf/otel-collector-config.yaml:/etc/otel-collector-config.yaml
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    environment:
      - OTEL_RESOURCE_ATTRIBUTES=host.name=signoz-host,os.type=linux
      - DOCKER_MULTI_NODE_CLUSTER=false
      - LOW_CARDINAL_EXCEPTION_GROUPING=false
    ports:
      # - "1777:1777"     # pprof extension
      - "4317:4317" # OTLP gRPC receiver
      - "4318:4318" # OTLP HTTP receiver
      # - "8888:8888"     # OtelCollector internal metrics
      # - "8889:8889"     # signoz spanmetrics exposed by the agent
      # - "9411:9411"     # Zipkin port
      # - "13133:13133"   # health check extension
      # - "14250:14250"   # Jaeger gRPC
      # - "14268:14268"   # Jaeger thrift HTTP
      # - "55678:55678"   # OpenCensus receiver
      # - "55679:55679"   # zPages extension
    restart: on-failure
    <<: *clickhouse-depend

  otel-collector-metrics:
    image: signoz/signoz-otel-collector:${OTELCOL_TAG:-0.66.7}
    command: [ "--config=/etc/otel-collector-metrics-config.yaml" ]
    volumes:
      - ./signoz_conf/otel-collector-metrics-config.yaml:/etc/otel-collector-metrics-config.yaml
    # ports:
    #   - "1777:1777"     # pprof extension
    #   - "8888:8888"     # OtelCollector internal metrics
    #   - "13133:13133"   # Health check extension
    #   - "55679:55679"   # zPages extension
    restart: on-failure
    <<: *clickhouse-depend

  users:
    build:
      dockerfile: Dockerfile
      context: ../../users
      # Only will build development stage from our dockerfile
      target: development
    volumes:
      - ../../users:/usr/src/app
      - ../../proto/users/users.proto:/usr/src/proto/users/users.proto
    # env_file:
    # - .env
    # Run a command against the development stage of the image
    command: pnpm run start:dev
    ports:
      - 3000:3000
      - 5000:5000

volumes:
  eventstore-volume-data:
  eventstore-volume-logs:
